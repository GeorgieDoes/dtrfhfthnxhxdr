<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Software Testing Quiz Game (Lectures 1â€“5)</title>
<style>
    body {
        font-family: Arial, sans-serif;
        background: #111;
        color: #eee;
        max-width: 900px;
        margin: auto;
        padding: 20px;
    }
    h1 {
        text-align: center;
    }
    .question {
        font-size: 1.25em;
        margin-bottom: 15px;
    }
    .option {
        background: #222;
        padding: 12px;
        margin: 8px 0;
        border-radius: 5px;
        cursor: pointer;
        border: 1px solid #444;
    }
    .option:hover {
        background: #333;
    }
    .correct {
        background: #1e7f3b;
        border-color: #2ecc71;
    }
    .wrong {
        background: #7f1e1e;
        border-color: #e74c3c;
    }
    .status {
        margin-top: 12px;
        font-weight: bold;
        font-size: 1.1em;
    }
    .explanation {
        margin-top: 12px;
        padding: 10px;
        background: #222;
        border-left: 4px solid #f1c40f;
    }
    button {
        margin-top: 20px;
        padding: 10px 20px;
        font-size: 1em;
        cursor: pointer;
    }
</style>
</head>
<body>

<h1>ðŸŽ¯ Software Testing Quiz (Lectures 1â€“5)</h1>

<div id="quiz">
    <div class="question" id="question"></div>
    <div id="options"></div>
    <div class="status" id="status"></div>
    <div class="explanation" id="explanation" style="display:none;"></div>
    <button id="nextBtn" style="display:none;">Next Question</button>
</div>

<script>
const quiz = [
// -------- LECTURE 1 --------
{
q:"What is the main goal of testing?",
options:["Prove system correctness","Discover software defects","Write project documentation","Generate source code"],
correct:1,
explanation:"Testing aims to discover defects by comparing actual and expected behaviour."
},
{
q:"Can testing prove the absence of bugs?",
options:["Yes, with 100% coverage","Yes, using formal methods","No, only shows presence","Yes, using mutation tests"],
correct:2,
explanation:"Testing can only reveal bugs, not prove their absence (Dijkstra)."
},
{
q:"What is an Error in software testing?",
options:["A static bug in code","An observable failure","Incorrect internal state","A missing test case"],
correct:2,
explanation:"An error is the incorrect program state that results from executing a fault."
},
{
q:"What question does Validation answer?",
options:["Build the product right?","Build the right product?","Does the code compile?","Is performance optimal?"],
correct:1,
explanation:"Validation ensures the product meets customer expectations and needs."
},
{
q:"What question does Verification answer?",
options:["Build the product right?","Build the right product?","Enough tests written?","Is the customer happy?"],
correct:0,
explanation:"Verification checks conformance to functional and non-functional requirements."
},
{
q:"In the RIP model, what does 'I' stand for?",
options:["Injection","Infection","Inspection","Isolation"],
correct:1,
explanation:"RIP stands for Reachability, Infection, and Propagation."
},
{
q:"What is a Fault?",
options:["Dynamic state flaw","Observable behaviour","Static flaw in code","A runtime crash"],
correct:2,
explanation:"A fault (bug) is a static flaw in the source code."
},
{
q:"What is a Failure?",
options:["A static source bug","Internal error state","Observable behaviour","Missing requirement"],
correct:2,
explanation:"A failure is the external, observable incorrect behaviour resulting from an error state."
},
{
q:"What is a Test Oracle?",
options:["Generator of tests","The truth mechanism","Results database","A flaky test"],
correct:1,
explanation:"An oracle decides if observed behaviour matches expected behaviour."
},
{
q:"What does the 'P' in RIP model stand for?",
options:["Performance","Propagation","Priority","Persistence"],
correct:1,
explanation:"The P stands for Propagation - the error must propagate to program output."
},
{
q:"What is Reachability in the RIP model?",
options:["Fault location hit","Coverage percentage","Test execution time","Mutation score"],
correct:0,
explanation:"Reachability means the test must execute the location containing the fault."
},
{
q:"How is Reliability defined in this context?",
options:["Success probability","100% test coverage","Zero bugs found","Execution speed"],
correct:0,
explanation:"Reliability is the probability of successful execution on a randomly selected element from the input domain."
},
{
q:"Which testing level focuses on individual methods or classes?",
options:["System Testing","Integration Testing","Unit Testing","Beta Testing"],
correct:2,
explanation:"Unit testing checks small pieces of code like methods or classes in isolation."
},
{
q:"What characterizes Black-box testing?",
options:["Known internal code","Unknown structure","Memory leak test","Assumed correctness"],
correct:1,
explanation:"Black-box testing examines the system from the outside based on specifications."
},
{
q:"What is White-box testing based on?",
options:["User requirements","Internal structure","External specs","Random inputs"],
correct:1,
explanation:"White-box testing uses knowledge of internal implementation and structure."
},
{
q:"What is regression testing?",
options:["Test new features","Rerunning old tests","Performance testing","Initial system test"],
correct:1,
explanation:"Regression testing ensures existing functionality still works after changes."
},
{
q:"What is Integration Testing?",
options:["Individual units","Unit interactions","User acceptance","Performance level"],
correct:1,
explanation:"Integration testing checks how different components work together."
},

// -------- LECTURE 2 --------
{
q:"What is unit testing?",
options:["Whole system test","Isolated unit test","Only UI testing","Performance test"],
correct:1,
explanation:"Unit testing targets a single unit (method/class/component) in isolation."
},
{
q:"What is the main benefit of unit testing?",
options:["System validation","Fast localization","User acceptance","Security testing"],
correct:1,
explanation:"Unit tests provide quick feedback and make it easy to pinpoint where faults occur."
},
{
q:"What is test independence?",
options:["Tests share state","Order independent","Specific sequence","Tests are coupled"],
correct:1,
explanation:"Independent tests can run in any order without affecting each other's results."
},
{
q:"Which of the following can unit testing be?",
options:["Strictly manual","Strictly automated","Manual or automated","Strictly random"],
correct:2,
explanation:"Unit tests can be manual or automated."
},
{
q:"What does a failing unit test indicate?",
options:["The test is wrong","Code won't compile","Unexpected output","Missing requirement"],
correct:2,
explanation:"A failing test means the code behaves unexpectedly for that specific input."
},
{
q:"Why should test inputs be simplified?",
options:["Increase randomness","Reduce runtime","Ease of debugging","Increase coverage"],
correct:2,
explanation:"Simpler input makes it easier to debug and locate faults."
},
{
q:"What is an executable specification?",
options:["Documentation","Tests as behavior","UML diagrams","User stories"],
correct:1,
explanation:"Tests describe expected behaviour in executable form."
},
{
q:"Why should tests cover as little code as possible?",
options:["Reduced runtime","Avoid mocking","Precise localization","Reduce test count"],
correct:2,
explanation:"Small focused tests make fault localization easier."
},
{
q:"Why are fast-running tests important?",
options:["Better docs","Fast regression","Mutation score","Requirement check"],
correct:1,
explanation:"Fast tests allow frequent and quick regression testing."
},
{
q:"Why is asserting exact output stronger than asserting types?",
options:["More readable","Faster run","More fault detection","Less coupling"],
correct:2,
explanation:"Checking exact output detects incorrect behaviour, not just type correctness."
},
{
q:"Which is an X-Unit framework?",
options:["Cypress","Selenium","JUnit","Postman"],
correct:2,
explanation:"JUnit is a Java X-Unit testing framework."
},
{
q:"What is mocking mainly used for?",
options:["Better speed","Isolate dependencies","Randomize input","Higher coverage"],
correct:1,
explanation:"Mocks replace difficult dependencies to make testing easier."
},
{
q:"What is a test stub?",
options:["Failing test case","Predetermined logic","Performance utility","Documentation tool"],
correct:1,
explanation:"Stubs provide canned answers to calls made during tests."
},
{
q:"What is a test spy?",
options:["Security monitor","Recording mock","Random generator","Coverage utility"],
correct:1,
explanation:"Spies record information about how they were called for verification."
},
{
q:"What is a flaky test?",
options:["Always failing","Non-deterministic","Has no assertions","Fast execution"],
correct:1,
explanation:"Flaky tests sometimes pass and sometimes fail without code changes."
},
{
q:"What does dependency injection improve?",
options:["Code coverage","Test decoupling","Syntax clarity","Run performance"],
correct:1,
explanation:"Dependency injection removes hard-coded dependencies, improving testability."
},
{
q:"Which code is indeterministic?",
options:["Pure functions","Static logic","Random or time","Isolated logic"],
correct:2,
explanation:"Random and time-based code produces different outputs for same input."
},
{
q:"What is the core idea of TDD?",
options:["Write code first","Write test first","Avoid refactor","Manual tests"],
correct:1,
explanation:"TDD enforces writing tests before implementation."
},
{
q:"What are the steps of TDD?",
options:["Plan-Code-Deploy","Design-Run-Main","Red-Green-Refactor","Test-Release-Fix"],
correct:2,
explanation:"Red: failing test, Green: make it pass, Refactor: clean code."
},
{
q:"What is the Red phase in TDD?",
options:["Fix code bugs","Write failing test","Refactor logic","Deploy feature"],
correct:1,
explanation:"Red phase: write a test that fails because the feature doesn't exist yet."
},
{
q:"What is the Green phase in TDD?",
options:["Write docs","Pass the test","Optimise code","Review logic"],
correct:1,
explanation:"Green phase: write just enough code to make the test pass."
},
{
q:"What is code smell?",
options:["Syntax error","Design problem","Speed issues","Security hole"],
correct:1,
explanation:"Code smell indicates potential design or quality issues that may need refactoring."
},

// -------- LECTURE 3 --------
{
q:"When is a test suite considered adequate?",
options:["All paths hit","Tests all pass","Cover requirements","100% mutation"],
correct:2,
explanation:"Adequacy requires every requirement to be tested."
},
{
q:"What is statement coverage?",
options:["Lines executed","Count of tests","Written lines","Documentation"],
correct:0,
explanation:"Statement coverage measures the percentage of code statements executed by tests."
},
{
q:"What is branch coverage?",
options:["Function count","Decision paths","Code complexity","Execution time"],
correct:1,
explanation:"Branch coverage measures how many decision paths (true/false) are tested."
},
{
q:"What is path coverage?",
options:["All code paths","The main path","The error path","Random paths"],
correct:0,
explanation:"Path coverage aims to test all possible paths through the code."
},
{
q:"Which is NOT a coverage type?",
options:["Statement","Method","Component","Mutation"],
correct:3,
explanation:"Mutation is a testing technique, not basic code coverage."
},
{
q:"Why is some code hard to test?",
options:["Run is fast","No coupling","External state","High coverage"],
correct:2,
explanation:"External resources introduce state, timing, and configuration issues."
},
{
q:"What is a smoke test?",
options:["Minimal check","UI scenario","Speed metric","Old regression"],
correct:0,
explanation:"Smoke tests check for obvious failures without detailed assertions."
},
{
q:"What does mutation testing measure?",
options:["Run speed","Readability","Fault find rate","Exec order"],
correct:2,
explanation:"Mutation testing checks if tests catch injected defects."
},
{
q:"What is a mutant in mutation testing?",
options:["New test case","Injected fault","Failed testing","Coverage data"],
correct:1,
explanation:"A mutant is the program with a small, deliberate fault introduced."
},
{
q:"What does it mean if a mutant is 'killed'?",
options:["Build failure","Fault detected","Mutant escaped","Test deleted"],
correct:1,
explanation:"A killed mutant means the test suite successfully detected the injected fault."
},
{
q:"What is a surviving mutant?",
options:["Passing test","Escaped fault","Correct logic","High coverage"],
correct:1,
explanation:"Surviving mutants indicate faults the test suite failed to detect."
},
{
q:"What is the mutation score?",
options:["Exec speed","Killed mutants","Test volume","Code complexity"],
correct:1,
explanation:"Mutation score = killed mutants / total mutants, measuring test effectiveness."
},
{
q:"Checked coverage focuses on:",
options:["Total lines","Asserted lines","Total tests","Logic depth"],
correct:1,
explanation:"Only code affecting assertions matters."
},
{
q:"What is cyclomatic complexity?",
options:["Test volume","Path count","Line count","Variable count"],
correct:1,
explanation:"Cyclomatic complexity measures the number of linearly independent paths."
},
{
q:"Why is 100% code coverage not sufficient?",
options:["Runtime slow","Logic missed","Cost is high","Manual work"],
correct:1,
explanation:"Coverage measures execution, not correctness - you still need good assertions."
},

// -------- LECTURE 4 --------
{
q:"What is test traceability?",
options:["Run speed","Requirement link","Reduced count","Randomness"],
correct:1,
explanation:"Traceability connects tests to requirements and code."
},
{
q:"What is a test case?",
options:["Bug report","Defined setup","Framework","Code metric"],
correct:1,
explanation:"A test case specifies inputs, execution conditions, and expected outcomes."
},
{
q:"What is a test suite?",
options:["Single test","Test grouping","Testing tool","Environment"],
correct:1,
explanation:"A test suite is a collection of test cases grouped together."
},
{
q:"Which is non-functional testing?",
options:["Login check","CRUD logic","Performance","Business rules"],
correct:2,
explanation:"Performance is a non-functional requirement."
},
{
q:"Goal of equivalence partitioning?",
options:["Test all data","Representative","Invalid only","White-box"],
correct:1,
explanation:"Equivalent inputs behave similarly, reducing needed tests."
},
{
q:"What are equivalence classes?",
options:["Bug types","Input groups","Run times","Metrics"],
correct:1,
explanation:"Equivalence classes group inputs that should produce similar behavior."
},
{
q:"What is the goal of boundary value analysis?",
options:["Random data","Partition edges","Median data","Ignore edges"],
correct:1,
explanation:"Boundaries between partitions are where bugs commonly occur."
},
{
q:"Boundary value analysis tests:",
options:["Random data","Typical data","Edges of range","Internal logic"],
correct:2,
explanation:"Boundaries are common sources of bugs."
},
{
q:"What is exploratory testing?",
options:["Randomized","Hybrid study","Manual only","Performance"],
correct:1,
explanation:"Exploratory testing involves learning about the system while designing and executing tests."
},
{
q:"What is a test scenario?",
options:["User workflow","One assertion","Code metric","Bug report"],
correct:0,
explanation:"Test scenarios describe high-level user interactions and workflows."
},
{
q:"What is acceptance testing?",
options:["Unit level","Needs validation","Speed check","Code review"],
correct:1,
explanation:"Acceptance testing validates the system satisfies business requirements and user needs."
},
{
q:"What is alpha testing?",
options:["User testing","Internal test","Speed check","Security scan"],
correct:1,
explanation:"Alpha testing is done by internal teams before external release."
},
{
q:"What is beta testing?",
options:["Real environment","Developer test","Automated only","Performance"],
correct:0,
explanation:"Beta testing involves real users testing in actual usage conditions."
},

// -------- LECTURE 5 --------
{
q:"What is a test strategy?",
options:["A bug list","Goal achieving","Case details","Plan update"],
correct:1,
explanation:"Strategy defines how testing goals are reached using available means."
},
{
q:"What is a test plan?",
options:["Source code","Process doc","Bug tracker","Automated test"],
correct:1,
explanation:"A test plan documents objectives, scope, approach, resources, and schedule."
},
{
q:"What should a test plan include?",
options:["Only tests","Full scope","Source code","User help"],
correct:1,
explanation:"Test plans cover scope, objectives, approach, resources, schedule, and risks."
},
{
q:"Which testing level is cheapest and fastest?",
options:["Acceptance","System","Integration","Unit"],
correct:3,
explanation:"Unit tests are cheap, fast, and automated."
},
{
q:"Why is traceability important in a test plan?",
options:["Run speed","Failure link","Reduce docs","Regression"],
correct:1,
explanation:"Traceability helps understand what failed and why."
},
{
q:"What does BDD emphasize?",
options:["Total coverage","User behavior","Code mutation","Static check"],
correct:1,
explanation:"BDD focuses on user behaviour and shared understanding."
},
{
q:"What language does BDD typically use?",
options:["Java code","Given format","SQL queries","Assembler"],
correct:1,
explanation:"BDD uses Given-When-Then (Gherkin) syntax for readable test scenarios."
},
{
q:"What is the purpose of Given-When-Then?",
options:["Optimisation","Human readable","Database query","Speed testing"],
correct:1,
explanation:"Given (context), When (action), Then (outcome) creates readable test specifications."
},
{
q:"What is continuous integration (CI)?",
options:["Manual only","Frequent merging","Annual deploy","Code review"],
correct:1,
explanation:"CI automatically builds and tests code with each integration."
},
{
q:"What is continuous delivery (CD)?",
options:["Manual step","Auto release","Test phase","Code review"],
correct:1,
explanation:"CD automates the release process so software can be deployed reliably at any time."
},
{
q:"Why start testing early?",
options:["Delay work","Manual focus","Reduce risk","No automation"],
correct:2,
explanation:"Early testing reduces defects and cost."
},
{
q:"Which tool is mainly for API testing?",
options:["Selenium","Cypress","Postman","JUnit"],
correct:2,
explanation:"Postman is designed for API testing."
},
{
q:"Which tool runs tests inside the browser with real-time feedback?",
options:["Puppeteer","Cypress","Selenium","Postman"],
correct:1,
explanation:"Cypress runs directly in the browser."
},
{
q:"Selenium WebDriver is:",
options:["API tester","Unit tool","Browser tool","Mock library"],
correct:2,
explanation:"Selenium automates real browsers for end-to-end testing."
},
{
q:"What is the testing pyramid?",
options:["Severity levels","Test ratios","Exec order","Team rank"],
correct:1,
explanation:"Testing pyramid shows more unit tests at base, fewer integration, and even fewer E2E tests."
},
{
q:"What is end-to-end (E2E) testing?",
options:["Unit testing","User workflow","Speed only","Safety only"],
correct:1,
explanation:"E2E testing validates entire workflows from user perspective."
},
{
q:"What is a smoke test in deployment?",
options:["Speed test","Critical check","Security scan","Full regression"],
correct:1,
explanation:"Smoke tests quickly verify basic functionality after deployment."
},
{
q:"What is load testing?",
options:["User volume","Target unit","Code quality","Security check"],
correct:0,
explanation:"Load testing checks system behavior under expected user traffic."
},
{
q:"What is stress testing?",
options:["Normal load","Over capacity","Code styling","Manual help"],
correct:1,
explanation:"Stress testing pushes the system beyond normal limits to find breaking points."
},
{
q:"What is the purpose of a test environment?",
options:["Live deploy","Isolated setup","Target editor","Bug tracking"],
correct:1,
explanation:"Test environments provide controlled settings separate from production."
},
{
q:"What is test automation?",
options:["Manual only","Tool based","Written docs","Code review"],
correct:1,
explanation:"Test automation uses scripts and tools to run tests without manual intervention."
},
// -------- ADDITIONAL QUESTIONS --------
{
q:"What is the 'Pesticide Paradox' in software testing?",
options:["Resistant bugs","Limited finding","Tool overload","Manual efficiency"],
correct:1,
explanation:"If the same tests are repeated, they will eventually stop finding new bugs."
},
{
q:"What is 'Exhaustive Testing'?",
options:["Tester fatigue","All input combos","Main path only","Single execution"],
correct:1,
explanation:"Exhaustive testing is generally impossible due to the infinite number of input and condition combinations."
},
{
q:"What defines the 'Absence-of-errors' fallacy?",
options:["Zero bug hype","Unavoidable bug","Useless audit","Easy detection"],
correct:0,
explanation:"A system with no bugs can still be a failure if it's unusable or doesn't meet requirements."
},
{
q:"Which of these is a type of Static Testing?",
options:["Unit level test","Code inspection","Performance check","Integration step"],
correct:1,
explanation:"Static testing involves examining code or documentation without executing the program."
},
{
q:"What is a 'Fake' object in the context of test doubles?",
options:["Logic stub","Simplified app","Recorder mock","Input source"],
correct:1,
explanation:"Fakes have working implementations but usually take shortcuts (e.g., an in-memory database)."
},
{
q:"What is the primary goal of 'Decision Table Testing'?",
options:["Table integrity","Condition mix","UI layout level","Basic coverage"],
correct:1,
explanation:"Decision tables are used to model complex business rules where multiple conditions affect outcomes."
},
{
q:"What does 'State Transition Testing' focus on?",
options:["Memory use","System changes","Schema shift","UI animation"],
correct:1,
explanation:"It focuses on the transitions between different states of the system based on specific inputs."
},
{
q:"How would you describe 'Error Guessing'?",
options:["Use AI help","Past experience","Random clicking","Random input"],
correct:1,
explanation:"Experienced testers use their intuition and past knowledge to target likely error-prone areas."
},
{
q:"Which of these is considered a non-functional testing type?",
options:["Boundary scan","Usability test","Input grouping","Code coverage"],
correct:1,
explanation:"Usability, security, and performance are non-functional attributes of a system."
},
{
q:"What is 'Sanity Testing' usually used for?",
options:["Mental check","Bug fix check","Full feature","User criteria"],
correct:1,
explanation:"Sanity testing is a quick, deep check to verify that a specific bug fix or change works as expected."
},
{
q:"A 'Fagan Inspection' is what type of testing activity?",
options:["Auto pentest","Static review","Speed profile","Security audit"],
correct:1,
explanation:"Fagan inspection is a formal, highly structured static testing process."
},
{
q:"In BDD, what does a 'Feature' usually represent?",
options:["Small function","User capability","Single report","Unit test case"],
correct:1,
explanation:"A Feature in BDD/Gherkin describes a high-level piece of functionality from the user's perspective."
},
{
q:"What is 'MTBF' (Mean Time Between Failures) used to measure?",
options:["System speed","Reliability rate","Maintenance cost","Safety level"],
correct:1,
explanation:"MTBF is a key metric used to quantify the reliability of a system."
},
{
q:"What is 'Grey-box testing'?",
options:["Zero knowledge","Partial detail","Interface only","Hardware logic"],
correct:1,
explanation:"Grey-box testing combines black-box inputs with partial knowledge of the internal code or database structure."
},
{
q:"What is the 'Golden Path' or 'Happy Path' in testing?",
options:["Costly suite","Expected flow","High stress","Covered logic"],
correct:1,
explanation:"The happy path is a test scenario that uses valid input and results in expected, error-free behavior."
}
];
// Shuffle the quiz questions for better studying
quiz.sort(() => Math.random() - 0.5);
let current = 0;
let score = 0;
let answered = false;

const qEl = document.getElementById("question");
const oEl = document.getElementById("options");
const sEl = document.getElementById("status");
const eEl = document.getElementById("explanation");
const nextBtn = document.getElementById("nextBtn");

function load() {
    answered = false;
    eEl.style.display = "none";
    nextBtn.style.display = "none";
    sEl.textContent = "";

    const q = quiz[current];
    qEl.textContent = `Q${current + 1}/${quiz.length}: ${q.q}`;
    oEl.innerHTML = "";

    // Create choices with original indices and shuffle them
    const choices = q.options.map((opt, i) => ({ text: opt, index: i }));
    choices.sort(() => Math.random() - 0.5);

    choices.forEach((choice) => {
        const d = document.createElement("div");
        d.className = "option";
        d.textContent = choice.text;
        d.dataset.index = choice.index; // Store original index
        d.onclick = () => answer(d, choice.index);
        oEl.appendChild(d);
    });
}

function answer(el, i) {
    if (answered) return;
    answered = true;

    const q = quiz[current];
    const opts = document.querySelectorAll(".option");

    // Highlight the correct one based on stored original index
    opts.forEach(opt => {
        if (parseInt(opt.dataset.index) === q.correct) {
            opt.classList.add("correct");
        }
    });

    if (i === q.correct) {
        score++;
        sEl.textContent = "âœ… Correct!";
    } else {
        el.classList.add("wrong");
        sEl.textContent = "âŒ Wrong!";
        eEl.style.display = "block";
        eEl.textContent = "Explanation: " + q.explanation;
    }

    nextBtn.style.display = "inline-block";
}

nextBtn.onclick = () => {
    current++;
    if (current < quiz.length) load();
    else {
        qEl.textContent = "ðŸŽ‰ Quiz Finished!";
        oEl.innerHTML = "";
        sEl.textContent = `Final Score: ${score} / ${quiz.length}`;
        eEl.style.display = "none";
        nextBtn.style.display = "none";
    }
};

load();
</script>

</body>
</html>